<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol.lst-kix_963bg4zi93n9-4{list-style-type:none}ol.lst-kix_963bg4zi93n9-5{list-style-type:none}.lst-kix_vj4atjyfq8tw-4>li{counter-increment:lst-ctn-kix_vj4atjyfq8tw-4}ol.lst-kix_963bg4zi93n9-2{list-style-type:none}.lst-kix_963bg4zi93n9-1>li:before{content:"" counter(lst-ctn-kix_963bg4zi93n9-1,lower-latin) ". "}.lst-kix_963bg4zi93n9-3>li:before{content:"" counter(lst-ctn-kix_963bg4zi93n9-3,decimal) ". "}ol.lst-kix_963bg4zi93n9-3{list-style-type:none}.lst-kix_vj4atjyfq8tw-1>li:before{content:"" counter(lst-ctn-kix_vj4atjyfq8tw-1,lower-latin) ". "}.lst-kix_vj4atjyfq8tw-3>li:before{content:"" counter(lst-ctn-kix_vj4atjyfq8tw-3,decimal) ". "}ol.lst-kix_vj4atjyfq8tw-7.start{counter-reset:lst-ctn-kix_vj4atjyfq8tw-7 0}ol.lst-kix_963bg4zi93n9-8{list-style-type:none}ul.lst-kix_j015jjymvce1-0{list-style-type:none}ol.lst-kix_963bg4zi93n9-1.start{counter-reset:lst-ctn-kix_963bg4zi93n9-1 0}ul.lst-kix_j015jjymvce1-1{list-style-type:none}ol.lst-kix_963bg4zi93n9-6{list-style-type:none}.lst-kix_963bg4zi93n9-0>li:before{content:"" counter(lst-ctn-kix_963bg4zi93n9-0,decimal) ". "}.lst-kix_963bg4zi93n9-4>li:before{content:"" counter(lst-ctn-kix_963bg4zi93n9-4,lower-latin) ". "}ol.lst-kix_963bg4zi93n9-7{list-style-type:none}.lst-kix_963bg4zi93n9-7>li{counter-increment:lst-ctn-kix_963bg4zi93n9-7}.lst-kix_vj4atjyfq8tw-0>li:before{content:"" counter(lst-ctn-kix_vj4atjyfq8tw-0,decimal) ". "}.lst-kix_vj4atjyfq8tw-4>li:before{content:"" counter(lst-ctn-kix_vj4atjyfq8tw-4,lower-latin) ". "}ol.lst-kix_963bg4zi93n9-8.start{counter-reset:lst-ctn-kix_963bg4zi93n9-8 0}ul.lst-kix_j015jjymvce1-4{list-style-type:none}ul.lst-kix_j015jjymvce1-5{list-style-type:none}ul.lst-kix_j015jjymvce1-2{list-style-type:none}.lst-kix_963bg4zi93n9-5>li:before{content:"" counter(lst-ctn-kix_963bg4zi93n9-5,lower-roman) ". "}.lst-kix_963bg4zi93n9-7>li:before{content:"" counter(lst-ctn-kix_963bg4zi93n9-7,lower-latin) ". "}.lst-kix_vj4atjyfq8tw-5>li:before{content:"" counter(lst-ctn-kix_vj4atjyfq8tw-5,lower-roman) ". "}.lst-kix_vj4atjyfq8tw-7>li:before{content:"" counter(lst-ctn-kix_vj4atjyfq8tw-7,lower-latin) ". "}ul.lst-kix_j015jjymvce1-3{list-style-type:none}ol.lst-kix_963bg4zi93n9-0{list-style-type:none}ul.lst-kix_j015jjymvce1-8{list-style-type:none}ol.lst-kix_963bg4zi93n9-1{list-style-type:none}.lst-kix_963bg4zi93n9-1>li{counter-increment:lst-ctn-kix_963bg4zi93n9-1}ol.lst-kix_vj4atjyfq8tw-0.start{counter-reset:lst-ctn-kix_vj4atjyfq8tw-0 0}ul.lst-kix_j015jjymvce1-6{list-style-type:none}ol.lst-kix_963bg4zi93n9-4.start{counter-reset:lst-ctn-kix_963bg4zi93n9-4 0}.lst-kix_963bg4zi93n9-6>li:before{content:"" counter(lst-ctn-kix_963bg4zi93n9-6,decimal) ". "}.lst-kix_vj4atjyfq8tw-6>li:before{content:"" counter(lst-ctn-kix_vj4atjyfq8tw-6,decimal) ". "}ul.lst-kix_j015jjymvce1-7{list-style-type:none}ol.lst-kix_vj4atjyfq8tw-6{list-style-type:none}.lst-kix_j015jjymvce1-2>li:before{content:"\0025a0  "}ol.lst-kix_vj4atjyfq8tw-5{list-style-type:none}ol.lst-kix_vj4atjyfq8tw-8{list-style-type:none}ol.lst-kix_vj4atjyfq8tw-7{list-style-type:none}ol.lst-kix_vj4atjyfq8tw-2{list-style-type:none}.lst-kix_j015jjymvce1-0>li:before{content:"\0025cf  "}.lst-kix_j015jjymvce1-4>li:before{content:"\0025cb  "}ol.lst-kix_vj4atjyfq8tw-1{list-style-type:none}ol.lst-kix_vj4atjyfq8tw-3.start{counter-reset:lst-ctn-kix_vj4atjyfq8tw-3 0}ol.lst-kix_vj4atjyfq8tw-4{list-style-type:none}.lst-kix_j015jjymvce1-3>li:before{content:"\0025cf  "}.lst-kix_963bg4zi93n9-8>li:before{content:"" counter(lst-ctn-kix_963bg4zi93n9-8,lower-roman) ". "}ol.lst-kix_vj4atjyfq8tw-3{list-style-type:none}.lst-kix_vj4atjyfq8tw-8>li:before{content:"" counter(lst-ctn-kix_vj4atjyfq8tw-8,lower-roman) ". "}.lst-kix_vj4atjyfq8tw-3>li{counter-increment:lst-ctn-kix_vj4atjyfq8tw-3}ol.lst-kix_vj4atjyfq8tw-0{list-style-type:none}.lst-kix_963bg4zi93n9-0>li{counter-increment:lst-ctn-kix_963bg4zi93n9-0}.lst-kix_j015jjymvce1-1>li:before{content:"\0025cb  "}ol.lst-kix_963bg4zi93n9-0.start{counter-reset:lst-ctn-kix_963bg4zi93n9-0 0}.lst-kix_j015jjymvce1-8>li:before{content:"\0025a0  "}.lst-kix_j015jjymvce1-7>li:before{content:"\0025cb  "}ol.lst-kix_vj4atjyfq8tw-1.start{counter-reset:lst-ctn-kix_vj4atjyfq8tw-1 0}.lst-kix_j015jjymvce1-6>li:before{content:"\0025cf  "}.lst-kix_vj4atjyfq8tw-6>li{counter-increment:lst-ctn-kix_vj4atjyfq8tw-6}.lst-kix_j015jjymvce1-5>li:before{content:"\0025a0  "}.lst-kix_963bg4zi93n9-2>li{counter-increment:lst-ctn-kix_963bg4zi93n9-2}ol.lst-kix_vj4atjyfq8tw-4.start{counter-reset:lst-ctn-kix_vj4atjyfq8tw-4 0}.lst-kix_963bg4zi93n9-8>li{counter-increment:lst-ctn-kix_963bg4zi93n9-8}ol.lst-kix_963bg4zi93n9-3.start{counter-reset:lst-ctn-kix_963bg4zi93n9-3 0}.lst-kix_963bg4zi93n9-5>li{counter-increment:lst-ctn-kix_963bg4zi93n9-5}ol.lst-kix_963bg4zi93n9-6.start{counter-reset:lst-ctn-kix_963bg4zi93n9-6 0}.lst-kix_963bg4zi93n9-2>li:before{content:"" counter(lst-ctn-kix_963bg4zi93n9-2,lower-roman) ". "}.lst-kix_vj4atjyfq8tw-7>li{counter-increment:lst-ctn-kix_vj4atjyfq8tw-7}.lst-kix_963bg4zi93n9-4>li{counter-increment:lst-ctn-kix_963bg4zi93n9-4}.lst-kix_vj4atjyfq8tw-1>li{counter-increment:lst-ctn-kix_vj4atjyfq8tw-1}ol.lst-kix_963bg4zi93n9-2.start{counter-reset:lst-ctn-kix_963bg4zi93n9-2 0}.lst-kix_vj4atjyfq8tw-0>li{counter-increment:lst-ctn-kix_vj4atjyfq8tw-0}ol.lst-kix_vj4atjyfq8tw-6.start{counter-reset:lst-ctn-kix_vj4atjyfq8tw-6 0}ol.lst-kix_vj4atjyfq8tw-8.start{counter-reset:lst-ctn-kix_vj4atjyfq8tw-8 0}ol.lst-kix_963bg4zi93n9-7.start{counter-reset:lst-ctn-kix_963bg4zi93n9-7 0}.lst-kix_963bg4zi93n9-3>li{counter-increment:lst-ctn-kix_963bg4zi93n9-3}ol.lst-kix_963bg4zi93n9-5.start{counter-reset:lst-ctn-kix_963bg4zi93n9-5 0}.lst-kix_963bg4zi93n9-6>li{counter-increment:lst-ctn-kix_963bg4zi93n9-6}ol.lst-kix_vj4atjyfq8tw-5.start{counter-reset:lst-ctn-kix_vj4atjyfq8tw-5 0}.lst-kix_vj4atjyfq8tw-2>li{counter-increment:lst-ctn-kix_vj4atjyfq8tw-2}.lst-kix_vj4atjyfq8tw-8>li{counter-increment:lst-ctn-kix_vj4atjyfq8tw-8}.lst-kix_vj4atjyfq8tw-5>li{counter-increment:lst-ctn-kix_vj4atjyfq8tw-5}.lst-kix_vj4atjyfq8tw-2>li:before{content:"" counter(lst-ctn-kix_vj4atjyfq8tw-2,lower-roman) ". "}ol.lst-kix_vj4atjyfq8tw-2.start{counter-reset:lst-ctn-kix_vj4atjyfq8tw-2 0}ol{margin:0;padding:0}table td,table th{padding:0}.c18{-webkit-text-decoration-skip:none;color:#000000;font-weight:400;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:16pt;font-family:"Arial";font-style:normal}.c6{padding-top:0pt;text-indent:36pt;padding-bottom:0pt;line-height:1.5;orphans:2;widows:2;text-align:left}.c7{margin-left:28pt;padding-top:15pt;padding-bottom:15pt;line-height:1.5;orphans:2;widows:2;text-align:left}.c24{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:"Arial";font-style:normal}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c4{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:26pt;font-family:"Arial";font-style:normal}.c16{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c10{padding-top:0pt;padding-bottom:3pt;line-height:1.5;page-break-after:avoid;orphans:2;widows:2;text-align:center}.c5{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:13pt;font-family:"Arial";font-style:normal}.c2{padding-top:18pt;padding-bottom:6pt;line-height:1.5;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c15{color:#434343;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Arial";font-style:normal}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c9{padding-top:0pt;padding-bottom:0pt;line-height:1.5;text-indent:36pt;text-align:center;height:11pt}.c22{padding-top:16pt;padding-bottom:4pt;line-height:1.5;page-break-after:avoid;text-align:left}.c14{padding-top:0pt;padding-bottom:16pt;line-height:1.5;text-indent:36pt;text-align:left}.c3{text-decoration-skip-ink:none;font-size:12pt;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c25{padding-top:18pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;text-align:left}.c26{padding-top:0pt;padding-bottom:0pt;line-height:1.5;text-align:center}.c8{padding-top:0pt;padding-bottom:0pt;line-height:1.5;text-align:left}.c19{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:center}.c21{background-color:#ffffff;max-width:468pt;margin: 0 auto !important; float: none !important;}.c23{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;text-decoration:underline}.c11{color:inherit;text-decoration:inherit}.c12{orphans:2;widows:2}.c13{font-size:12pt}.c20{text-indent:36pt}.c17{height:11pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body style="text-align: center !important; padding-top: 10px;" class="c21">
    <div style=" max-width: 300px; border-radius: 1px; border-style: solid;margin: 0 auto !important; float: none !important;">
        <div style="padding: 1rem;">
            <a href="https://github.com/Kadynm49/shrek-cloud/blob/master/final/movie-reviewer.py" style="color: ;">Source Code</a></br>
            <a href="https://github.com/Kadynm49/shrek-cloud/blob/master/final/FinalReport.pdf">Final Report (pdf format)</a></br>
        </div>
    </div></br></br>

    <div style="text-align: center;"><p class="c10 title" id="h.nca7usv9lw2y"><span class="c4">Movie-Reviewer Final Report</span></p></div><p class="c19 c12"><span class="c5">Zephren de la Cerda </span></p><p class="c12 c19"><span class="c5">Kadyn Marshall</span></p><h2 class="c2" id="h.fddl82ikwcan"><span class="c18">Abstract</span></h2><p class="c8 c12"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c0">We created a program that generates a review based off of the user reviews on IMDb. The user gives the program the name of the movie, and whether they would like a positive or negative review. The program will generate language models from the user reviews and generate a new review for each of the three models we used; trigram, markov chains and machine learning. As a result, the movies that had a higher review counter produced higher quality reviews. Between the models, with the same data set, the trigram model was one of the faster models with reviews that almost sounded like they could be written by a human. The machine learning and markov model produced readable but nonsensical reviews. </span></p><p class="c8 c12 c17"><span class="c16"></span></p><h2 class="c2" id="h.qxx76bvle8j7"><span class="c18">Introduction/Motivation</span></h2><p class="c8 c12"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c0">Our motivation for this project was to see if we could generate a movie review that fit the following three criteria: a review that made sense, described specific details about the movie, and gave a positive or negative connotation. We believed if we could generate a movie review that met these goals, then it would be comparable to real movie reviews written by real people. </span></p><p class="c8 c12 c17"><span class="c16"></span></p><h2 class="c2" id="h.960g54go5574"><span class="c18">Related Work</span></h2><p class="c14"><span class="c0">A lot of similar work has been done on fake text generation. Some examples include fake amazon product reviews and fake news generation. The models that are commonly used are N-grams, markov models, and recently neural networks have attracted a lot of attention in this field. After researching and reading several articles that describe these methods in detail, we decided to try using all three of these models for our review generation. For the N-gram model, we used our implementation of tri-grams from assignment 2. For the Markov model we used an implementation from an online article. For the Neural network we used a package called textgenrnn. These sources can be found in the references section.</span></p><p class="c14"><span class="c0">Recurrent Neural Networks (RNNs) have attracted a lot of attention for their ability to solve complex machine learning problems. RNNs fundamentally differ from other types of neural networks, such as simple feed-forward networks or Convolutional Neural Networks, because the current state of the network is &ldquo;remembered&rdquo; and fed in as an input to the next time step.</span></p><h2 class="c2" id="h.8rt1jzl3k7zl"><span class="c23">System Description</span></h2><h3 class="c22 c12" id="h.5mbuq6i7hifq"><span class="c15">Data</span></h3><p class="c14"><span class="c0">When deciding on a dataset to use for our movie generator, we first looked at a few free sets online that had millions of reviews in them, but they were limited to a smaller set of movies because the reviews were only collected between a limited set of years. We thought about all of the online sources with expansive collections of movie data and reviews, such as Rotten Tomatoes, Metacritic, and IMDb. This led us to think: If this is where millions of people go to write and read reviews, then why can&rsquo;t we just use those as our dataset? After some research, we decided to create our own dataset by scraping reviews straight from IMDb&rsquo;s user reviews web page on the spot when the program is run. This allows for a more dynamic dataset that grows with time as movies are released and more people write reviews.</span></p><p class="c14"><span class="c13">Since Movie-Reviewer fetches the dataset at runtime, the dataset and corpora are not static. Therefore we cannot simply provide a link to the dataset. Instead, we will provide an example of what the data looks like, and then expand on how our program retrieves the data in the implementation section.</span></p><p class="c8 c12"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 322.67px;"><img alt="" src="images/image1.png" style="width: 624.00px; height: 322.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c6"><span class="c13">Here is an example of one of the thousands of reviews we pull straight from IMDb. Each review has a title, and a rating along with it. This rating is what we used to determine whether the review was negative or positive. Having this rating associated with each review allowed us to divide the reviews into three corpora: one for just the negative reviews, one for the positive, and one that contains all of the reviews.</span></p><p class="c14 c17"><span class="c0"></span></p><h3 class="c22 c12" id="h.9e7mp0nzaedm"><span class="c15">Implementation and Algorithm</span></h3><p class="c8 c20"><span class="c0">The first step that the program takes is to collect input from the user. It prompts the user for the movie title, the type of review they want (negative, positive, or average), and which models they would like Movie-Reviewer to use. The program then uses an API called OMDb (see references) retrieve IMDb&rsquo;s movie ID for the user provided movie title. Once we had the movie&rsquo;s ID, we just had to append it to a specific URL like so:</span></p><p class="c8 c20 c17"><span class="c0"></span></p><p class="c20 c26"><span class="c0">&#39;https://www.imdb.com/title/&#39; + imdbID + &#39;/reviews/&#39;</span></p><p class="c9"><span class="c0"></span></p><p class="c8 c20"><span class="c0">Once we figured out how to programmatically retrieve the URL, we had to figure out how to parse the HTML and extract the reviews. This part was mostly about figuring out how the html was structured, but the real challenge came when we discovered that the site only loads 25 reviews at a time and requires the user to click the &ldquo;Load More&rdquo; button to load the next 25. We knew 25 reviews wouldn&rsquo;t be nearly enough for generating our models, and if we weren&rsquo;t able to figure out how to load all of them then we would have to look for data elsewhere. </span></p><p class="c8 c20"><span class="c0">By tracking the network flow when clicking on the load more button, we noticed that it was actually making a request to a different URL. After more digging in the HTML we notice that the load button has an attribute called data-key that contains the key to the next 25 reviews. Appending the key to the ajaxurl, also provided by an attribute in the load more button, gives the URL to retrieve the next 25 reviews. Here is the html tag for the load more button, which includes its attributes:</span></p><p class="c8 c17 c20"><span class="c0"></span></p><p class="c8"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 25.33px;"><img alt="" src="images/image3.png" style="width: 624.00px; height: 25.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c8 c20"><span class="c0">After this discovery, we wrote the code to read 25 reviews, fetch the next 25, then read those and so on until all reviews were read and we had our corpus. From there we were able to separate the reviews into two separate corpora, and feed them into the models that the user specified should be used. </span></p><p class="c8 c20"><span class="c0">Trigram model tracks three tokens at a time, and uses the previous two tokens to predict the next token. It chooses the 5 most likely tokens to come next, and then picks a random one. The markov chain uses a similar approach, in that it uses the current word to predict the next word, but there are more probabilities involved that determine the most likely next word to be used (see reference for more information). The implementations of the Trigram model and Markov model were modified so that it produces a review that is the average length of all the reviews. The Neural Network model was not modified as it is a complex package that we could only use right out of the box. </span></p><h3 class="c22" id="h.1jx5yfnmy9zn"><span class="c15">Experiment setup</span></h3><p class="c8 c12"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c0">To test the accuracy of models, we ran two types of experiments. The first one was using movies that varied from release date, genre, and number of written reviews on IMDb. We wanted to see if our generated reviews would be higher quality if we have the models more words to train on, and if the reviews would be more mature or immature depending on the movie it was writing. We also wanted to see if we could trick people into believing that our generated reviews were written by a real human. </span></p><h2 class="c12 c25" id="h.ibgskm6s38wd"><span class="c18">Evaluation and Discussion</span></h2><p class="c1"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 430.67px;"><img alt="" src="images/image4.png" style="width: 585.12px; height: 361.33px; margin-left: 0.00px; margin-top: -4.13px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title="Points scored"></span></p><p class="c8 c12"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c13">The results of our experiment were quite surprising. We expected the Neural Network to produce the highest quality movie reviews compared to the Trigram and Markov model, although this was not the case. The machine learning model took hours to run, as the other two models only took minutes, and the results were very disappointing for the first few movies we ran it on. The Markov model was also a bit disappointing, some of the reviews were readable but did not make any sense. The trigram model was our winner, we noticed there was a threshold for the number of reviews needed for an output that made sense, and once that threshold was met (around 2,000 reviews), every review it generated was very close to a human review. We were even able to fool some of our classmates that believed our computer generated reviews were real. For our first test, we used one real review that was posted on IMDB (red), and two fake reviews generated by our trigram model (blue and orange). Only 62.5% of the class guessed correctly. For the second test, the review written by a human was blue, so only 41.2% of the class guessed correctly. </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 590.66px; height: 442.50px;"><img alt="" src="images/image2.png" style="width: 590.66px; height: 442.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h2 class="c2" id="h.bafxwschao31"><span class="c18">Conclusion and Future Work</span></h2><p class="c6"><span class="c0">The Movie-Reviewer project was a success. It uses a dynamic dataset, it creates reviews that make sense and express sentiment, and it was able to fool people into thinking its reviews were written by a human. We are proud that we were able to pull it together in a few week period, and that we overcame the challenges involved in using a non-static dataset. The results of the different models were unexpected, but satisfactory nonetheless. The Trigram model exceeded our expectations, and the Neural Network model produced disappointing reviews. We suspect that this has to do with the amount of time that we let the model train on the data before producing the review. We left it at the minimum while conducting our experiment, because it still would take over an hour to run for the movies with thousands of reviews. In the future, we would like to let the model take its time to train longer and see if the results improve. </span></p><p class="c6"><span class="c0">Aside from trying to improve the models, we would like to make a few other changes that would improve the program as a whole. We would like to also feed the review titles to the models, so that fake review titles are generated along with the fake reviews. We would also like to improve the movie search feature, because as of now it is impossible for the user to know which movie is being reviewed when they enter in a title such as &ldquo;Batman&rdquo; because there are many batman movies on IMDb. Finally, once we have made all of the discussed improvements, we would like to host the application on a web server and create a simple UI so that the project is accessible to anyone online.</span></p><h2 class="c2" id="h.xjfqlzmdfi3j"><span class="c18">References</span></h2><p class="c7"><span class="c13">Minimaxir. (2020, April 28). Minimaxir/textgenrnn. Retrieved May 27, 2020, from </span><span class="c3"><a class="c11" href="https://www.google.com/url?q=https://github.com/minimaxir/textgenrnn&amp;sa=D&amp;ust=1591920140517000">https://github.com/minimaxir/textgenrnn</a></span><span class="c0">&nbsp;</span></p><p class="c7"><span class="c13">Build a Markov Chain Sentence Generator in 20 lines of Python - jeffcarp. (n.d.). Retrieved May 27, 2020, from </span><span class="c3"><a class="c11" href="https://www.google.com/url?q=https://www.jeffcarp.com/posts/2019/markov-chain-python/&amp;sa=D&amp;ust=1591920140517000">https://www.jeffcarp.com/posts/2019/markov-chain-python/</a></span><span class="c0">&nbsp;</span></p><p class="c7"><span class="c13">Shaver, B. (2017, December 29). Simulating Text With Markov Chains in Python. Retrieved May 27, 2020, from </span><span class="c3"><a class="c11" href="https://www.google.com/url?q=https://towardsdatascience.com/simulating-text-with-markov-chains-in-python-1a27e6d13fc6&amp;sa=D&amp;ust=1591920140517000">https://towardsdatascience.com/simulating-text-with-markov-chains-in-python-1a27e6d13fc6</a></span></p><p class="c7"><span class="c13">OMDb API. (n.d.). Retrieved May 27, 2020, from </span><span class="c3"><a class="c11" href="https://www.google.com/url?q=http://www.omdbapi.com/&amp;sa=D&amp;ust=1591920140518000">http://www.omdbapi.com/</a></span><span class="c0">&nbsp;</span></p><p class="c7 c17"><span class="c16"></span></p><p class="c8 c12 c17"><span class="c16"></span></p></body></html>
